{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "from maddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(random=True):\n",
    "    \n",
    "    # Reset the environment\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    # Get the current state\n",
    "    states = env_info.vector_observations\n",
    "    # Initialize the score to 0\n",
    "    scores = []\n",
    "    while True:\n",
    "        if random:\n",
    "            # Select a random action for the agent\n",
    "            actions = np.random.randn(num_agents, action_size) \n",
    "            # Clip the actions so that all actions are between -1 and 1\n",
    "            actions = np.clip(actions, -1, 1)                 \n",
    "        else:\n",
    "            # Select an action from making the agent act if random is not True\n",
    "            actions = get_actions(states, add_noise=False)\n",
    "        # Send actions to environment\n",
    "        env_info = env.step(actions)[brain_name]      \n",
    "        # Get the next states\n",
    "        next_states = env_info.vector_observations         \n",
    "        # Get the rewards\n",
    "        rewards = env_info.rewards                         \n",
    "        # Check if episode has finished\n",
    "        dones = env_info.local_done                     \n",
    "        # Update the scores and the states\n",
    "        scores, states = scores+env_info.rewards, next_states                        \n",
    "        # Exit loop if the episode has finished\n",
    "        if np.any(dones):                                 \n",
    "            break\n",
    "    \n",
    "    return round(np.max(scores), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for trial 1: 0.0\n",
      "Average score for trial 2: 0.0\n",
      "Average score for trial 3: 0.0\n",
      "Average score for trial 4: 0.0\n",
      "Average score for trial 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "trials = 5\n",
    "\n",
    "for trial in range(trials):\n",
    "    score = play()\n",
    "    print('Average score for trial {}: {}'.format(trial+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine the actions of both agents\n",
    "\n",
    "def get_actions(states, add_noise):\n",
    "    action_0 = agent_0.act(states, add_noise)\n",
    "    action_1 = agent_1.act(states, add_noise)\n",
    "    return np.concatenate((action_0, action_1), axis=0).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the agents with a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some common parameters to use\n",
    "print_every = 10\n",
    "add_noise = True\n",
    "\n",
    "num_states = state_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the agent we use an actor and a critic networks in a Multi-Agent Deep Deterministic Policy Gradient.\n",
    "\n",
    "Both the actor and critic networks use 2 fully connected layers of depth 256 and 128. Batch normalization is applied to the input of the intermediate layer.\n",
    "\n",
    "The hyper parameters used are the following:\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor\n",
    "\n",
    "LR_CRITIC = 1e-3        # learning rate of the critic\n",
    "\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "LEARN_EVERY = 10        # learning timestep interval\n",
    "\n",
    "LEARN_NUM = 5           # number of learning passes\n",
    "\n",
    "GAMMA = 0.99            # discount factor\n",
    "\n",
    "TAU = 3e-2              # for soft update of target parameters\n",
    "\n",
    "OU_SIGMA = 0.1          # Ornstein-Uhlenbeck noise parameter, volatility\n",
    "\n",
    "OU_THETA = 0.15         # Ornstein-Uhlenbeck noise parameter, speed of mean reversion\n",
    "\n",
    "EPS_START = 5.0         # initial value for epsilon in noise decay process in Agent.act()\n",
    "\n",
    "EPS_EP_END = 300        # episode to end the noise decay process\n",
    "\n",
    "EPS_FINAL = 0           # final value for epsilon after decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddpg(n_episodes=1500, max_t=1000, print_every=10):\n",
    "    \"\"\"Multi-Agent Deep Deterministic Policy Gradient (MADDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int)      : maximum number of training episodes\n",
    "        max_t (int)           : maximum number of timesteps per episode\n",
    "\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores_all = []\n",
    "    moving_average = []\n",
    "    best_score = -np.inf\n",
    "    best_episode = 0\n",
    "    solved = False\n",
    "    c_states = num_states * 2 # combine states\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = np.reshape(env_info.vector_observations, (1,c_states))\n",
    "        \n",
    "        agent_0.reset()\n",
    "        agent_1.reset()\n",
    "        \n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = get_actions(states, add_noise=True)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = np.reshape(env_info.vector_observations, (1,c_states))\n",
    "            rewards = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "            agent_0.step(states, actions, rewards[0], next_states, done, 0)\n",
    "            agent_1.step(states, actions, rewards[1], next_states, done, 1)\n",
    "            scores += np.max(rewards)\n",
    "            states = next_states\n",
    "            if np.any(done):\n",
    "                break\n",
    "\n",
    "        ep_best = np.max(scores)\n",
    "        scores_window.append(ep_best)\n",
    "        scores_all.append(ep_best)\n",
    "        moving_average.append(np.mean(scores_window))\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\tEpisode {}\\tMoving Average: {:.3f}'.format(i_episode, moving_average[-1]))\n",
    "\n",
    "        if moving_average[-1] >= 0.5: # Reached goal?\n",
    "            if not solved:\n",
    "                print('\\n\\tEnvironment solved in {:d} episodes! \\\n",
    "                \\n\\tMoving Average: {:.3f} (over past {:d} episodes)\\n'.format(\n",
    "                    i_episode-100, moving_average[-1], 100))\n",
    "                torch.save(agent_0.actor_local.state_dict(), 'checkpoint_agent_0.pth')\n",
    "                torch.save(agent_1.critic_local.state_dict(), 'checkpoint_agent_1.pth')\n",
    "                solved = True\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    return scores_all, moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agents\n",
    "agent_0 = Agent(state_size, action_size, num_agents=1, random_seed=0)\n",
    "agent_1 = Agent(state_size, action_size, num_agents=1, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpisode 10\tMoving Average: 0.000\n",
      "\tEpisode 20\tMoving Average: 0.005\n",
      "\tEpisode 30\tMoving Average: 0.003\n",
      "\tEpisode 40\tMoving Average: 0.005\n",
      "\tEpisode 50\tMoving Average: 0.004\n",
      "\tEpisode 60\tMoving Average: 0.003\n",
      "\tEpisode 70\tMoving Average: 0.004\n",
      "\tEpisode 80\tMoving Average: 0.004\n",
      "\tEpisode 90\tMoving Average: 0.003\n",
      "\tEpisode 100\tMoving Average: 0.003\n",
      "\tEpisode 110\tMoving Average: 0.004\n",
      "\tEpisode 120\tMoving Average: 0.005\n",
      "\tEpisode 130\tMoving Average: 0.011\n",
      "\tEpisode 140\tMoving Average: 0.010\n",
      "\tEpisode 150\tMoving Average: 0.010\n",
      "\tEpisode 160\tMoving Average: 0.012\n",
      "\tEpisode 170\tMoving Average: 0.018\n",
      "\tEpisode 180\tMoving Average: 0.022\n",
      "\tEpisode 190\tMoving Average: 0.025\n",
      "\tEpisode 200\tMoving Average: 0.026\n",
      "\tEpisode 210\tMoving Average: 0.029\n",
      "\tEpisode 220\tMoving Average: 0.030\n",
      "\tEpisode 230\tMoving Average: 0.029\n",
      "\tEpisode 240\tMoving Average: 0.039\n",
      "\tEpisode 250\tMoving Average: 0.043\n",
      "\tEpisode 260\tMoving Average: 0.048\n",
      "\tEpisode 270\tMoving Average: 0.046\n",
      "\tEpisode 280\tMoving Average: 0.048\n",
      "\tEpisode 290\tMoving Average: 0.052\n",
      "\tEpisode 300\tMoving Average: 0.058\n",
      "\tEpisode 310\tMoving Average: 0.059\n",
      "\tEpisode 320\tMoving Average: 0.066\n",
      "\tEpisode 330\tMoving Average: 0.071\n",
      "\tEpisode 340\tMoving Average: 0.069\n",
      "\tEpisode 350\tMoving Average: 0.077\n",
      "\tEpisode 360\tMoving Average: 0.083\n",
      "\tEpisode 370\tMoving Average: 0.092\n",
      "\tEpisode 380\tMoving Average: 0.096\n",
      "\tEpisode 390\tMoving Average: 0.099\n",
      "\tEpisode 400\tMoving Average: 0.103\n",
      "\tEpisode 410\tMoving Average: 0.112\n",
      "\tEpisode 420\tMoving Average: 0.116\n",
      "\tEpisode 430\tMoving Average: 0.122\n",
      "\tEpisode 440\tMoving Average: 0.126\n",
      "\tEpisode 450\tMoving Average: 0.128\n",
      "\tEpisode 460\tMoving Average: 0.128\n",
      "\tEpisode 470\tMoving Average: 0.123\n",
      "\tEpisode 480\tMoving Average: 0.126\n",
      "\tEpisode 490\tMoving Average: 0.134\n",
      "\tEpisode 500\tMoving Average: 0.131\n",
      "\tEpisode 510\tMoving Average: 0.133\n",
      "\tEpisode 520\tMoving Average: 0.153\n",
      "\tEpisode 530\tMoving Average: 0.161\n",
      "\tEpisode 540\tMoving Average: 0.159\n",
      "\tEpisode 550\tMoving Average: 0.174\n",
      "\tEpisode 560\tMoving Average: 0.179\n",
      "\tEpisode 570\tMoving Average: 0.192\n",
      "\tEpisode 580\tMoving Average: 0.216\n",
      "\tEpisode 590\tMoving Average: 0.364\n",
      "\tEpisode 600\tMoving Average: 0.479\n",
      "\n",
      "\tEnvironment solved in 502 episodes!                 \n",
      "\tMoving Average: 0.512 (over past 100 episodes)\n",
      "\n",
      "Time elapsed: 6.0min 11.39sec.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "scores, moving_average = maddpg()\n",
    "\n",
    "end = time.time()\n",
    "elapsed = (end - start)\n",
    "print(\"Time elapsed: {}min {:.2f}sec.\".format(elapsed//60, elapsed%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5aa44fc88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the scores\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(scores)), scores, label='DDPG')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Episode Number')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Future Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the agents, we could:\n",
    "1. Fine tune the hyperparameters some more\n",
    "2. Try more complex MARL architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
